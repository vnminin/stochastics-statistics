[
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Who may find these notes useful?\nOne may ask a reasonable question: “Why do we need yet another set of lecture notes with a fairly elementary treatment, from a modern probability theory point of view, of stochastic processes?” Indeed, there are already many books covering much of the material presented here. Moreover, we have borrowed material from many of these excellent texts, as the reader will see in our bibliographic remarks at the end of each chapter. So why did Peter Guttorp feel the need to write his “Stochastic Modeling of Scientific Data” book in the 90s (Guttorp 1995) and why did we feel the need to update this book with these lecture notes? The answer lies in the second part of the title of our lecture notes: we would like to show how statisticians think about stochastic processes when we use them to answer scientific questions.\nOur statistical point of view differs from many standard expositions of stochastic modeling because we emphasize thinking about the data generating processes carefully and focusing on properties of stochastic models needed in order to fit these models to data. For example, long term behavior of stochastic processes are of less interest when observations generated from theses processes are availalbe only during a short period of time. Therefore, statisticians are more interested in transient bevavior of stochastic processes: transition probabilities of Markov processes, first passage times, etc. Markov chain Monte Carlo algorithms offer one notable exception to this general rule. Emphasis on computationally relevant mathematical results is another feature of these notes. A mathematical result is deemed computationally relevant if it allows us to compute a property of the stochastic process of interest with reasonable efficiency to be used inside statistical algorithms.\nOur target audience is graduate students in Applied Mathematics, Computer Science, Engineering, and Statistics. In our classes, we also had many excellent mathematically prepared PhD students from Biological and Social Sciences who found the classes useful for their dissertation research. Most parts of these lecture notes follow the following structure:\nWe now introduce two stochastic models and pose mathematical and statistical questions that we would like the reader to be able to answer after mastering the material in these notes.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#who-may-find-these-notes-useful",
    "href": "intro.html#who-may-find-these-notes-useful",
    "title": "1  Introduction",
    "section": "",
    "text": "We introduce a class of stochastic processes and demonstrate what natural phenomena can be modelded by this class of models.\nNext, we describe how this class of stochastic processes can be “observed.” In other words, if we model a natural phenomenon with a stochastic process, we would like to show what kind observations/measurements we can realistically expect to be available to learn about this natural phenomenon.\nWe then demonstrate how to perform statistical inference with these types of data. This step usually inloves deriving the likelihood for the model and data in hand and devising a computationally feasible way to perform either maximum likelihood or Bayesian inference. In some cases we also discusss non-likelihood-based inference.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#motivating-examples",
    "href": "intro.html#motivating-examples",
    "title": "1  Introduction",
    "section": "1.2 Motivating Examples",
    "text": "1.2 Motivating Examples\nOur examples come from two disciplines with a long history of using stochastic models and developing statistical methods for fitting these models to data: population genetics and infectious disease dynamics. If the reader wants to learn more about mathematical and statistical developments in these disciplines we recommend the following texts: (Ewens 2004) and (Andersson and Britton 2012).\n\n1.2.1 Wright-Fisher model of genetic drift\n\n\n\n\n\n\nHistorical note \n\n\n\n\n\n\n Ronald Fisher1890–1962 \n\n\nBritish statistician and geneticist Ronald Fisher and American geneticist Sewall Wright, together with a British mathematical biologist, Jack Haldane, laid a foundation for what is now known as modern evolutionary synthesis — a theory that reconciled seeming discrepancies between Darwinian and Mendelian schools of thought on evolution and natural selection. The Wright-Fisher model and its various modifications played a pivotal role in this synthesis. \n\n\n Sewall Wrigth1889–1988\n\n\n\n\n\nConsider a population of \\(m\\) individuals. All individuals are diploid, meaning that each member of the population carries two copies of their chromosomes. Suppose we are interested in a particular “gene” on one of the chromosomes. Here, a “gene” is loosely defined as stretch of DNA, not necessarily a protein coding region. Since our population is diploid, we have \\(2m\\) genes in total. Suppose that the gene under consideration has only two possible variants, called alleles in genetics: \\(A\\) and \\(a\\). Let \\(X_n\\) be the number of \\(A\\) alleles in the population at generation \\(n\\). We assume that there is no selection acting on our gene, so we are interested in random fluctuations of allele frequencies under neutrality. We also assume that the population size stays constant and that individuals in the population mate at random with each other. Under all these assumptions, it is reasonable to postulate the following stochastic mechanism for changes in allele counts. During each reproductive cycle, the genes of the next generation are obtained by sampling with replacement genes from the previous generation. To keep the population size constant, the number of samples is equal to \\(2m\\). Figure Figure 1.1 shows an example of such processes for a population of 5 individuals (10 genes) and 4 generations. This stochastic process is called the Wright-Fisher model in population genetics (Fisher 1930; Wright 1931).\n\n\n\n\n\n\nFigure 1.1: Wright-Fisher model diagram. The plot shows five generations of the Wright-Fisher process in a population of 10 individuals. Each row represents alleles (circles) in a particular generation. Lines connecting circles denote sampling with replacement. The number of \\(A\\) alleles for each generation is shown next to each row.\n\n\n\nAs we will see in later chapters, it is easy to simulate realizations of processes like the Wright-Fisher model. Figure 1.2 shows three random trajectories of the Wright-Fisher model, each starting with its own value for the intial condition \\(X_0\\). For these simulations, we set the population size to \\(m=50\\) (100 genes) and evolved the system for 40 generations. Notice that by construction, \\(X_n\\) will eventually get absorbed into either \\(X_{\\infty} =0\\) or \\(X_{\\infty} = 2m\\). However, after a finite number of generations it may end up with any value between 0 and \\(2m\\).\n\n\n\n\n\n\n\n\nFigure 1.2: Three random realizations of the Wright-Fisher process, tracking the number of \\(A\\) alleles for 40 generations.\n\n\n\n\n\nUsing tools from stochastic modeling, we would like to answer the following questions:\n\nWhat is the probability that \\(X_n\\) get absorbed in \\(X_{\\infty} =0\\) vs. \\(X_{\\infty} = 2m\\)?\nHow quickly (in how many steps) does the absorption occur?\nHow can we extend this model to achieve non-trivial allele frequencies (\\(0 &lt; X_{\\infty} &lt; 2m\\)) in the population at equilibrium?\n\n\n\n1.2.2 Susceptible-Infected-Recovered (SIR) epidemic model\n\n\n\n\n\n\nHistorical note \n\n\n\n\n\n\n Anderson GrayMcKendrick1876-1943 \n\n\nIn 1766 the Swiss mathematician and physicist Daniel Bernolli used mathematics to argue for the benefits of vaccination against smallpox. Anderson Gray McKendrick was a Scottish army officer, director of the Pasteur Institute 1920-1926, and after that superintendent of the Royal College of Physicians’ laboratory, Edinburgh. In 1914 he published the first account of a pure birth process. His 1926 DSc dissertation at Aberdeen was entitled “Applications of mathematics to medical problems” and may be the first stochastic model of an epidemic (although Bailey (1986) mentions a probabilistic model by an Estonian physician named En’ko in 1889). \n\n\n Norman T.J. Bailey1923–2007\n\n\n\nThe modern stochastic epidemic theory was essentially created by Norman T. J. Bailey, an English statistician who spent most of his career at Oxford and the World Health Organization in Geneva (Armitage and Bithell 2009).\n\n\nConsider a population of \\(N\\) individuals. Let \\(I_t\\) be the number of individuals infected with a pathogen (e.g., influenza virus), \\(S_t\\) be the number of susceptible individuals, and \\(R_t\\) be the number of recovered or removed invividuals. Assuming that infected individuals become infected immediately once infected and setting an initial condition for the system (e.g., \\(I_0=1\\), \\(S_0= N-1\\), and \\(R_t=0\\)), we would like to model the state of the epidemic, \\((I_t, S_t, R_t)\\) as a continuous-time stochastic process. We further assume that recovered individuals stay recovered forever, the system is closed and that the population size stays constant: \\(I_t  + S_t + R_t = N\\). Transmission and recovery events happen at random times; only one event is allowed to happen instanteously at a particular time. The rates are constant across time. We will be able to complete the mathematical construction of this process when we get to continuous-time Markov chains in Chapter 6. This model is called an SIR model in infectious disease epidemiology.\n\n\n\n\n\n\nFigure 1.3: SIR model cartoon. The plot shows 4 times points (not necessarily evenly spaced) during an epidemic in the population with 10 individuals. Susceptible individuals are shown in blue, infectious individuals are shown in red, and recovered individuals are shown in black.\n\n\n\nWe are interested in answering the following questions:\n\nHow to define this Markov process so it can produce reasonable stochastic behavior of an epidemic in a closed population?\nWhat is the distribution of the total number of individuals that become infected during the course of the epidemic?\nWhat is the probability that all individuals in the population become infected?\nHow can we infer parameters of the SIR model given partial information about infected/uninfected status of individuals in the populations?\nHow do we make forecasts about progression of the epidemic given noisy data during the initial stage of the epidemic?\n\nNotice that the last two questions usually fall outside of the scope of a typical book on applied probability and/or stochastic processes. Our exposition of stochastic processes is different in that we are primarily interested in applications of stochastic processes to data analyses arising in sciences.\n\n\n\n\n\nThree random realizations of the Susceptible-Infectious-Recovered (SIR) stochastic epidemic model.\n\n\n\n\n\n\n\n\n\nAndersson, H., and T. Britton. 2012. Stochastic Epidemic Models and Their Statistical Analysis. Vol. 151. Springer Science & Business Media.\n\n\nArmitage, P., and J. F. Bithell. 2009. “Norman Thomas John Bailey, 1923–2007.” Journal of the Royal Statistical Society Series A: Statistics in Society 172 (3): 689–90.\n\n\nBailey, J. 1986. “An Improbable Path.” In The Craft of Probabilistic Modeling: A Collection of Personal Accounts, edited by J. Gani, 64–87. Berlin: Springer-Verlag.\n\n\nEwens, W. J. 2004. Mathematical Population Genetics. 2nd ed. New York: Springer.\n\n\nFisher, R. A. 1930. The Genetical Theory of Natural Selection. Oxford: Clarendon Press.\n\n\nGuttorp, P. 1995. Stochastic Modeling of Scientific Data. Suffolk, Great Britain: Chapman & Hall.\n\n\nWright, S. 1931. “Evolution in Mendelian Populations.” Genetics 16: 97–159.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Andersson, H., and T. Britton. 2012. Stochastic Epidemic Models and\nTheir Statistical Analysis. Vol. 151. Springer Science &\nBusiness Media.\n\n\nArmitage, P., and J. F. Bithell. 2009. “Norman Thomas John Bailey,\n1923–2007.” Journal of the Royal Statistical Society Series\nA: Statistics in Society 172 (3): 689–90.\n\n\nBailey, J. 1986. “An Improbable Path.” In The Craft of\nProbabilistic Modeling: A Collection of Personal Accounts, edited\nby J. Gani, 64–87. Berlin: Springer-Verlag.\n\n\nDurret, R. 2004. Probability: Theory and Examples. Third.\nDuxbury Press.\n\n\nEwens, W. J. 2004. Mathematical Population Genetics. 2nd ed.\nNew York: Springer.\n\n\nFisher, R. A. 1930. The Genetical Theory of Natural Selection.\nOxford: Clarendon Press.\n\n\nGuttorp, P. 1995. Stochastic Modeling of Scientific Data.\nSuffolk, Great Britain: Chapman & Hall.\n\n\nWright, S. 1931. “Evolution in Mendelian Populations.”\nGenetics 16: 97–159.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "ctmc_background.html",
    "href": "ctmc_background.html",
    "title": "6  Continuous-Time Markov Chain Background",
    "section": "",
    "text": "Under construction, but coming online soon.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Continuous-Time Markov Chain Background</span>"
    ]
  },
  {
    "objectID": "dtmc_stat.html",
    "href": "dtmc_stat.html",
    "title": "5  Statistical Inference for Discrete-Time Markov Chains",
    "section": "",
    "text": "Under construction, but coming online soon.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistical Inference for Discrete-Time Markov Chains</span>"
    ]
  },
  {
    "objectID": "stat_refresh.html",
    "href": "stat_refresh.html",
    "title": "4  Statistics Refresher",
    "section": "",
    "text": "Under construction, but coming online soon.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Statistics Refresher</span>"
    ]
  },
  {
    "objectID": "dtmc_background.html",
    "href": "dtmc_background.html",
    "title": "3  Discrete-Time Markov Chain Background",
    "section": "",
    "text": "Under construction, but coming online soon.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Discrete-Time Markov Chain Background</span>"
    ]
  },
  {
    "objectID": "prob_refresh.html#footnotes",
    "href": "prob_refresh.html#footnotes",
    "title": "2  Probability Refresher",
    "section": "",
    "text": "We use the term state space, which is frequently used in stochastic processes theory. In probability textbooks the term sample space is more common.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability Refresher</span>"
    ]
  },
  {
    "objectID": "prob_refresh.html#example",
    "href": "prob_refresh.html#example",
    "title": "2  Probability Refresher",
    "section": "2.1 Example",
    "text": "2.1 Example\nLet \\(\\Omega = \\{1,2,\\dots,n\\}\\), we define \\(\\text{Pr}\\left(A \\right) = |A|/n\\), where \\(|A|\\) is the number of elements in \\(A \\in \\Omega\\). For example, if \\(n=10\\), then \\(\\text{Pr}\\left(\\{1\\} \\right) = 0.1\\) and \\(\\text{Pr}\\left(\\{2,9,10\\} \\right) = 0.3\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability Refresher</span>"
    ]
  },
  {
    "objectID": "prob_refresh.html",
    "href": "prob_refresh.html",
    "title": "2  Probability Refresher",
    "section": "",
    "text": "2.1 Events, Probabilities, and Random Variables\nWe assume that we can assign probabilities to events — outcomes of a random experiment. For example, tossing a coin results in one of two possible events: H =“heads” and T=“tails.” More formally, we define events as certain subsets of some abstract space.\nNext, we need to be able to assign probabilities to events. This is done by introducing a probability measure.\nIn the case of countable \\(\\Omega\\) we can define \\(\\text{Pr}(\\cdot)\\) for all subsets, while if the cardinality is larger we have to restrict attention to certain subsets, called measuarble (Durret 2004).\nWe also need a concept of a random variable. Informally, a random variable \\(X\\) is a function or variable, whose value is generated by a random experiment. For example, we can define a binary random variable associated with a toss of a coin: \\[\\begin{equation*}\nX =\n\\begin{cases}\n1 &\\text{ if heads},\\\\\n0 &\\text{ if tails}.\n\\end{cases}\n\\end{equation*}\\]\nMore generally:\nA fully formal defition of a random variable involves a concept of measurability, which we would like to avoid defining at this point.\nLater in the notes, we will see random variables satisfying \\(\\text{Pr}(X = \\infty) &gt; 0\\). Hence, we map \\(\\Omega\\) to \\(\\bar{\\mathbb{R}} = \\mathbb{R}\\bigcup\\{\\pm\\infty\\}\\).\nNote that there is an alternative definition of the geometric distribution does not count the successful trial so that \\(\\text{Pr}\\left(N=n \\right) = (1-p)^np \\text{ for } n=0,1,\\dots\\)\nWe defined all discrete random variables above using probabilities of \\(X\\) taking a particular value. A function that assigns probabilities to random variable values is called a probability mass function. However, a more general way to define random variables is by specifying a cumulative distribution function.\nProperties of cdf:\nFigure 2.1: Probability mass function (pmf) and cumulative distribution functions (cdf) for the discrete uniform random variable over the integer set \\(\\{1,2,\\dots,10\\}\\)\nmy.s.prob=0.2\n\nplot(c(0:14), dgeom(c(0:14),prob=my.s.prob), type=\"h\", xlab=\"X\", ylab=\"\", main=\"Geometric pmf\", axes=FALSE, ylim=c(0,1), lwd=2)\naxis(1, at=c(0:14))\naxis(2)\nbox()\n\n\n\n\n\n\n\nx&lt;-0:14\ncdf&lt;-pgeom(x,prob=my.s.prob)\n\nleftPointX = c(-0.5,x) \nleftPointY = c(0,cdf)\nrightPointX = c(x,14.5)\nrightPointY = c(0, cdf)\nplot(1,1,type=\"n\", xlim=c(-0.5,14.5), ylim = c(0,1),xlab=\"X\", ylab=\"\", main=\"Geometric cdf\")\nsegments(leftPointX, leftPointY, rightPointX-0.2, rightPointY,lwd=2)\npoints(x,c(0,cdf[-15]), cex=1.3)\npoints(x,cdf, cex=1.3, pch=19)\n\n\n\n\n\n\n\n#par(mfrow=c(2,2), cex.lab=1.4, cex.axis=1.4, cex.main=1.4)\nplot(1, 1, type=\"n\", main=\"Continuous uniform pdf\",\n     axes=FALSE, xlab=\"U\", ylab=\"Density\", ylim=c(0,1), xlim=c(-0.5,1.5), lwd=2)\nsegments(0,1,1,1, lwd=2)\nsegments(-0.5,0,-0.05,0, lwd=2)\nsegments(1.05,0,1.5,0, lwd=2)\npoints(c(0,1), c(0,0), cex=1.3)\npoints(c(0,1), c(1,1), cex=1.3, pch=19)\naxis(1)\naxis(2)\nbox()\n\n\n\n\n\n\n\nplot(1, 1, type=\"n\", main=\"Continuous uniform cdf\",\n     axes=FALSE, xlab=\"U\", ylab=\"Probability\", ylim=c(0,1), xlim=c(-0.5,1.5), lwd=2)\nsegments(0,0,1,1, lwd=2)\nsegments(-0.5,0,0,0, lwd=2)\nsegments(1,1,1.5,1, lwd=2)\naxis(1)\naxis(2)\nbox()\n\n\n\n\n\n\n\nx.grid = c(0,1:1000)/100\nmy.lambda = 2.4\n\nplot(x.grid, dexp(x.grid, rate=my.lambda), type=\"l\", main=\"Exponential pdf\",\n     axes=FALSE, xlab=\"X\", ylab=\"Density\", xlim=c(0,3), lwd=2)\naxis(1)\naxis(2)\nbox()\n\n\n\n\n\n\n\nplot(x.grid, pexp(x.grid, rate=my.lambda), type=\"l\", main=\"Exponential cdf\",\n     axes=FALSE, xlab=\"X\", ylab=\"Probability\", ylim=c(0,1.0), xlim=c(0,3), lwd=2)\naxis(1)\naxis(2)\nbox()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability Refresher</span>"
    ]
  },
  {
    "objectID": "prob_refresh.html#events-and-random-variables",
    "href": "prob_refresh.html#events-and-random-variables",
    "title": "2  Probability Refresher",
    "section": "",
    "text": "Definition\n\n\n\nThe **s*tate space**1 \\(\\Omega\\) is a collection of all possible outcomes of a random experiment.\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA probability measure \\(\\text{Pr}(\\cdot)\\) is a function mapping subsets of \\(\\Omega\\) to real numbers, satisfying:\n\n\\(\\text{Pr}(\\Omega) = 1\\).\n\\(0 \\le \\text{Pr}(A) \\le 1\\) for all \\(A \\subset \\Omega\\).\n\\(\\text{Pr}\\left(\\bigcup_{i=1}^{\\infty} A_i \\right) =\n\\sum_{i=1}^{\\infty}\\text{Pr}(A_i)\\) for mutually exclusive events \\(A_1,A_2,\\dots\\)\n\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet \\(\\Omega = \\{1,2,\\dots,n\\}\\), we define \\(\\text{Pr}\\left(A \\right) = |A|/n\\), where \\(|A|\\) is the number of elements in \\(A \\in \\Omega\\). For example, if \\(n=10\\), then \\(\\text{Pr}\\left(\\{1\\} \\right) = 0.1\\) and \\(\\text{Pr}\\left(\\{2,9,10\\} \\right) = 0.3\\).\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA function \\(X(\\omega): \\Omega \\rightarrow \\bar{\\mathbb{R}}\\) that maps events to the extended real line is called a random variable (r.v.).\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nFor events \\(A\\) and \\(B\\) in \\(\\Omega\\) we define conditional probability as \\[\\begin{equation*}\n\\text{Pr}\\left(B \\,|\\,A\\right) = \\frac{\\text{Pr}\\left(A \\bigcap B \\right)}{\\text{Pr}\\left(A \\right)}.\n\\end{equation*}\\] If \\(\\text{Pr}\\left(B \\,|\\,A\\right) = \\text{Pr}\\left(B \\right)\\) we say that the events \\(A\\) and \\(B\\) are independent, which together with the formula above implies that \\(\\text{Pr}\\left(A \\bigcap B \\right) = \\text{Pr}\\left(A \\right) \\times \\text{Pr}\\left(B \\right)\\).\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nTwo r.v.s \\(X\\) and \\(Y\\) are called independent if the events \\(\\{X \\in A\\}\\) and \\(\\{Y \\in B\\}\\) are independent for all sets \\(A\\) and \\(B\\).\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA sequence \\(X_1, \\dots X_n\\) of random variables is called iid (independent and identically distributed) if they are mutually independent and have the same distribution.\n\n\n\n\n\n\n\n\nExample: Bernoulli r.v.\n\n\n\nRandom variable \\(X \\in \\{0,1\\}\\) with \\(\\text{Pr}\\left(X=1 \\right)=p\\), \\(\\text{Pr}\\left(X=0 \\right)=1-p\\) for \\(0 \\le p \\le 1\\) is called a Bernoulli random variable with parameter (or success probability) \\(p\\).\n\n\n\n\n\n\n\n\nExample: Binomial r.v.\n\n\n\nLet \\(X_1,\\dots,X_n\\) be \\(n\\) independent \\(\\text{Bernoulli}(p)\\) random variables. Then the number of successes \\(S_n = \\sum_{i=1}^n X_i\\) is called a binomial r.v. with \\[\\begin{equation*}\n  \\text{Pr}\\left(S_n=k \\right) = {n \\choose k} p^k (1-p)^{n-k}, k = 0,\\dots, n.\n  \\end{equation*}\\]\n\n\n\n\n\n\n\n\nExample: Geometric r.v.\n\n\n\nLet \\(X_1, X_2, \\dots\\) be and infinite number of independent \\(\\text{Bernoulli}(p)\\) random variables and \\(N = \\min\\{n: X_n=1\\}\\) be the number of trials until the first success occurs, including the successful trial. Then \\[\\begin{equation*}\n    \\text{Pr}\\left(N=n \\right) = (1-p)^{n-1}p  \\text{ for } n=1,2,\\dots\n    \\end{equation*}\\]\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\n\\(F(x) = \\text{Pr}\\left(X \\le x \\right)\\) is called the cumulative distribution function (cdf) of \\(X\\).\n\n\n\n\n\\(0 \\le F(x) \\le 1\\),\n\\(F(x) \\le F(y)\\) for \\(x \\le y\\),\n\\(\\lim_{x \\rightarrow y^{+}} F(x) = F(y)\\) (\\(F(x)\\) is right-continuous),\n\\(\\lim_{x \\rightarrow -\\infty} F(x) = \\text{Pr}\\left(X=-\\infty \\right)\\) (usually \\(=0\\)),\n\\(\\lim_{x \\rightarrow \\infty} F(x) = 1-\\text{Pr}\\left(X=\\infty \\right)\\) (usually \\(=1\\)),\n\\(\\text{Pr}\\left(X=x \\right) = F(x) - F(x-)\\) where \\(F(x-) = \\lim_{y \\uparrow x} F(y)\\).\n\n\n\n\n\n\n\nExample: Discrete uniform random variable\n\n\n\nFor a random variable \\(U\\), uniformly distributed over \\(\\{1,2,\\dots,n\\}\\), its cdf is given by \\[\\begin{equation*}\n  F(x) =\n  \\begin{cases}\n  0 &\\text{ if } x &lt; 1,\\\\\n1/n &\\text { if } 1 \\le x &lt; 2,\\\\\n  2/n &\\text { if } 2 \\le x &lt; 3,\\\\\n  &\\vdots\\\\\n(n-1)/n &\\text { if } n-1 \\le x &lt; n,\\\\\n  1 &\\text{ if } x \\ge n.\n  \\end{cases}\n  \\end{equation*}\\] The probability mass function and cdf of U, with \\(n=10\\), are shown in Figure~\\(\\ref{discr-unif-geometric}\\), which also contains the probability mass function and cdf of a geometric random variable.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability Refresher</span>"
    ]
  },
  {
    "objectID": "prob_refresh.html#expectations",
    "href": "prob_refresh.html#expectations",
    "title": "2  Probability Refresher",
    "section": "2.2 Expectations",
    "text": "2.2 Expectations",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability Refresher</span>"
    ]
  },
  {
    "objectID": "prob_refresh.html#events-probabilities-and-random-variables",
    "href": "prob_refresh.html#events-probabilities-and-random-variables",
    "title": "2  Probability Refresher",
    "section": "",
    "text": "Definition\n\n\n\nThe **s*tate space**1 \\(\\Omega\\) is a collection of all possible outcomes of a random experiment.\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA probability measure \\(\\text{Pr}(\\cdot)\\) is a function mapping subsets of \\(\\Omega\\) to real numbers, satisfying:\n\n\\(\\text{Pr}(\\Omega) = 1\\).\n\\(0 \\le \\text{Pr}(A) \\le 1\\) for all \\(A \\subset \\Omega\\).\n\\(\\text{Pr}\\left(\\bigcup_{i=1}^{\\infty} A_i \\right) =\n\\sum_{i=1}^{\\infty}\\text{Pr}(A_i)\\) for mutually exclusive events \\(A_1,A_2,\\dots\\)\n\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet \\(\\Omega = \\{1,2,\\dots,n\\}\\), we define \\(\\text{Pr}\\left(A \\right) = |A|/n\\), where \\(|A|\\) is the number of elements in \\(A \\in \\Omega\\). For example, if \\(n=10\\), then \\(\\text{Pr}\\left(\\{1\\} \\right) = 0.1\\) and \\(\\text{Pr}\\left(\\{2,9,10\\} \\right) = 0.3\\).\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA function \\(X(\\omega): \\Omega \\rightarrow \\bar{\\mathbb{R}}\\) that maps events to the extended real line is called a random variable (r.v.).\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nFor events \\(A\\) and \\(B\\) in \\(\\Omega\\) we define conditional probability as \\[\\begin{equation*}\n\\text{Pr}\\left(B \\,|\\,A\\right) = \\frac{\\text{Pr}\\left(A \\bigcap B \\right)}{\\text{Pr}\\left(A \\right)}.\n\\end{equation*}\\] If \\(\\text{Pr}\\left(B \\,|\\,A\\right) = \\text{Pr}\\left(B \\right)\\) we say that the events \\(A\\) and \\(B\\) are independent, which together with the formula above implies that \\(\\text{Pr}\\left(A \\bigcap B \\right) = \\text{Pr}\\left(A \\right) \\times \\text{Pr}\\left(B \\right)\\).\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nTwo r.v.s \\(X\\) and \\(Y\\) are called independent if the events \\(\\{X \\in A\\}\\) and \\(\\{Y \\in B\\}\\) are independent for all sets \\(A\\) and \\(B\\).\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA sequence \\(X_1, \\dots X_n\\) of random variables is called iid (independent and identically distributed) if they are mutually independent and have the same distribution.\n\n\n\n\n\n\n\n\nExample: Bernoulli r.v.\n\n\n\nRandom variable \\(X \\in \\{0,1\\}\\) with \\(\\text{Pr}\\left(X=1 \\right)=p\\), \\(\\text{Pr}\\left(X=0 \\right)=1-p\\) for \\(0 \\le p \\le 1\\) is called a Bernoulli random variable with parameter (or success probability) \\(p\\).\n\n\n\n\n\n\n\n\nExample: Binomial r.v.\n\n\n\nLet \\(X_1,\\dots,X_n\\) be \\(n\\) independent \\(\\text{Bernoulli}(p)\\) random variables. Then the number of successes \\(S_n = \\sum_{i=1}^n X_i\\) is called a binomial r.v. with \\[\\begin{equation*}\n  \\text{Pr}\\left(S_n=k \\right) = {n \\choose k} p^k (1-p)^{n-k}, k = 0,\\dots, n.\n  \\end{equation*}\\]\n\n\n\n\n\n\n\n\nExample: Geometric r.v.\n\n\n\nLet \\(X_1, X_2, \\dots\\) be and infinite number of independent \\(\\text{Bernoulli}(p)\\) random variables and \\(N = \\min\\{n: X_n=1\\}\\) be the number of trials until the first success occurs, including the successful trial. Then \\[\\begin{equation*}\n    \\text{Pr}\\left(N=n \\right) = (1-p)^{n-1}p  \\text{ for } n=1,2,\\dots\n    \\end{equation*}\\]\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\n\\(F(x) = \\text{Pr}\\left(X \\le x \\right)\\) is called the cumulative distribution function (cdf) of \\(X\\).\n\n\n\n\n\\(0 \\le F(x) \\le 1\\),\n\\(F(x) \\le F(y)\\) for \\(x \\le y\\),\n\\(\\lim_{x \\rightarrow y^{+}} F(x) = F(y)\\) (\\(F(x)\\) is right-continuous),\n\\(\\lim_{x \\rightarrow -\\infty} F(x) = \\text{Pr}\\left(X=-\\infty \\right)\\) (usually \\(=0\\)),\n\\(\\lim_{x \\rightarrow \\infty} F(x) = 1-\\text{Pr}\\left(X=\\infty \\right)\\) (usually \\(=1\\)),\n\\(\\text{Pr}\\left(X=x \\right) = F(x) - F(x-)\\) where \\(F(x-) = \\lim_{y \\uparrow x} F(y)\\).\n\n\n\n\n\n\n\nExample: Discrete uniform random variable\n\n\n\nFor a random variable \\(U\\), uniformly distributed over \\(\\{1,2,\\dots,n\\}\\), its cdf is given by \\[\\begin{equation*}\n  F(x) =\n  \\begin{cases}\n  0 &\\text{ if } x &lt; 1,\\\\\n1/n &\\text { if } 1 \\le x &lt; 2,\\\\\n  2/n &\\text { if } 2 \\le x &lt; 3,\\\\\n  &\\vdots\\\\\n(n-1)/n &\\text { if } n-1 \\le x &lt; n,\\\\\n  1 &\\text{ if } x \\ge n.\n  \\end{cases}\n  \\end{equation*}\\] The probability mass function and cdf of U, with \\(n=10\\), are shown in Figure 2.1, which also contains the probability mass function and cdf of a geometric random variable.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability Refresher</span>"
    ]
  },
  {
    "objectID": "prob_refresh.html#limit-theorems",
    "href": "prob_refresh.html#limit-theorems",
    "title": "2  Probability Refresher",
    "section": "2.3 Limit Theorems",
    "text": "2.3 Limit Theorems\n\n\n\n\nDurret, R. 2004. Probability: Theory and Examples. Third. Duxbury Press.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability Refresher</span>"
    ]
  }
]