[
  {
    "objectID": "prob_refresh.html",
    "href": "prob_refresh.html",
    "title": "2  Probability Refresher",
    "section": "",
    "text": "2.1 Events and their Probabilities\nA random experiment or process is one where deterministic prediction is difficult. A coin toss is an example of a random experiment. Random experiments generate simple events. For example, if you toss a coin twice, the simple events are: HH, HT, TH, TT, where H = heads and T = tails.\nFor the tossing a coin twice experiment, the sample space is \\(S=\\{HH, HT, TH, TT\\}\\).\nFor the coin-tossing experiment, we can define the following events:\nFor the two-coin-tossing example with events A and B:\nSince events are sets, it is often useful to visualize them with Venn diagrams.\nFigure 2.1: A Venn diagram showing two events of , \\(A=\\{HH, HT, TH\\}\\) and \\(B=\\{HT, TH, TT\\}\\), and their intersection \\(A \\cup B = \\{HT, TH\\}\\).\nThe De Morgan Laws allow us to take complements of unions and intersections of sets/events:\nIf events \\(A\\) and \\(B\\) cannot happen at the same time, they are called mutually exclusive. In set notations this means that their intersection is an empty set: \\(A \\cap B = \\emptyset\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability Refresher</span>"
    ]
  },
  {
    "objectID": "prob_refresh.html#events-and-their-probabilities",
    "href": "prob_refresh.html#events-and-their-probabilities",
    "title": "2  Probability Refresher",
    "section": "",
    "text": "Definition\n\n\n\nThe state space1 \\(\\Omega\\) is a collection of all possible outcomes of a random experiment.\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nAn event is any subset of the state space.\n\n\n\n\n\\(A = \\text{\"at least one H\"} \\Rightarrow A=\\{HH, HT, TH\\}\\)\n\\(B = \\text{\"at most one H\"} \\Rightarrow B=\\{HT, TH, TT\\}\\)\n\n\n\n\n\n\n\nDefinition of event/set arithmetic\n\n\n\n\n\\(A \\cup B = \\{\\text{simple events in A or B or both}\\}\\)\n\\(A \\cap B = \\{\\text{simple events in both A and B}\\}\\)\n\\(A^c = \\{\\text{simple events not in A}\\}\\)\n\n\n\n\n\n\\(A \\cup B = \\{HH, HT, TH, TT\\} = S\\) (the whole state space)\n\\(A \\cap B = \\{HT, TH\\}\\)\n\\(A^c = \\{TT\\}\\)\n\\(B^c = \\{HH\\}\\)\n\n\n\n\n\n\\((A \\cup B)^c = A^c \\cap B^c\\)\n\\((A \\cap B)^c = A^c \\cup B^c\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability Refresher</span>"
    ]
  },
  {
    "objectID": "prob_refresh.html#probability-axioms",
    "href": "prob_refresh.html#probability-axioms",
    "title": "2  Probability Refresher",
    "section": "2.2 Probability axioms",
    "text": "2.2 Probability axioms\n[cite_start]Probability is a function that maps events to real numbers between 0 and 1[cite: 110, 114, 115, 116, 117, 118].\nThe probability axioms are: 1. [cite_start]For any event \\(A \\subset S\\), \\(0 \\le P(A) \\le 1\\)[cite: 121, 122, 125, 126]. 2. [cite_start]\\(P(S) = 1\\)[cite: 122]. 3. [cite_start]For mutually exclusive events A and B (\\(A \\cap B = \\emptyset\\)), \\(P(A \\cup B) = P(A) + P(B)\\)[cite: 127].\n[cite_start]The General Addition Rule is: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)[cite: 127].\n[cite_start]The Law of Complementary Events is: \\(P(A^c) = 1 - P(A)\\)[cite: 132].\n\n2.2.1 Example: practicing addition rule\nSuppose we know the following probabilities for students in a Stats 67 class: * [cite_start]Probability of being right-handed: \\(P(A) = 0.8\\) [cite: 144] * [cite_start]Probability of being a CS major: \\(P(B) = 0.87\\) [cite: 144] * [cite_start]Probability of being both right-handed and a CS major: \\(P(A \\cap B) = 0.75\\) [cite: 144, 145]\n[cite_start]What is the probability that a student is either right-handed, a CS major, or both? [cite: 146, 147, 148, 149, 150, 151]\nWe can use the addition rule: [cite_start]\\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\) [cite: 159] [cite_start]\\(P(A \\cup B) = 0.8 + 0.87 - 0.75 = 0.92\\) [cite: 160]\n[cite_start]Next question: What is the probability that a Stats 67 student is a left-handed CS major? [cite: 161, 162, 163, 164, 165, 166, 167] [cite_start]We need to find \\(P(A^c \\cap B)\\), where \\(A^c\\) represents a student who is not right-handed (i.e., left-handed)[cite: 169, 170].\n[cite_start]A useful trick to remember is that for any events A and B, we can write \\(B = (A^c \\cap B) \\cup (A \\cap B)\\)[cite: 175]. Since \\((A^c \\cap B)\\) and \\((A \\cap B)\\) are disjoint, we can apply the addition rule: [cite_start]\\(P(B) = P(A^c \\cap B) + P(A \\cap B)\\) [cite: 186]\nNow we can solve for \\(P(A^c \\cap B)\\): [cite_start]\\(P(A^c \\cap B) = P(B) - P(A \\cap B)\\) [cite: 193] [cite_start]\\(P(A^c \\cap B) = 0.87 - 0.75 = 0.12\\) [cite: 193, 195]\nWe assume that we can assign probabilities to events — outcomes of a random experiment. For example, tossing a coin results in one of two possible events: H =“heads” and T=“tails.” More formally, we define events as certain subsets of some abstract space.\nNext, we need to be able to assign probabilities to events. This is done by introducing a probability measure.\n\n\n\n\n\n\nDefinition\n\n\n\nA probability measure \\(\\text{Pr}(\\cdot)\\) is a function mapping subsets of \\(\\Omega\\) to real numbers, satisfying:\n\n\\(\\text{Pr}(\\Omega) = 1\\).\n\\(0 \\le \\text{Pr}(A) \\le 1\\) for all \\(A \\subset \\Omega\\).\n\\(\\text{Pr}\\left(\\bigcup_{i=1}^{\\infty} A_i \\right) =\n\\sum_{i=1}^{\\infty}\\text{Pr}(A_i)\\) for mutually exclusive events \\(A_1,A_2,\\dots\\)\n\n\n\nIn the case of countable \\(\\Omega\\) we can define \\(\\text{Pr}(\\cdot)\\) for all subsets, while if the cardinality is larger we have to restrict attention to certain subsets, called measuarble (Durret 2004).\n\n\n\n\n\n\nExample\n\n\n\nLet \\(\\Omega = \\{1,2,\\dots,n\\}\\), we define \\(\\text{Pr}\\left(A \\right) = |A|/n\\), where \\(|A|\\) is the number of elements in \\(A \\in \\Omega\\). For example, if \\(n=10\\), then \\(\\text{Pr}\\left(\\{1\\} \\right) = 0.1\\) and \\(\\text{Pr}\\left(\\{2,9,10\\} \\right) = 0.3\\).\n\n\nWe also need a concept of a random variable. Informally, a random variable \\(X\\) is a function or variable, whose value is generated by a random experiment. For example, we can define a binary random variable associated with a toss of a coin: \\[\\begin{equation*}\nX =\n\\begin{cases}\n1 &\\text{ if heads},\\\\\n0 &\\text{ if tails}.\n\\end{cases}\n\\end{equation*}\\]\nMore generally:\n\n\n\n\n\n\nDefinition\n\n\n\nA function \\(X(\\omega): \\Omega \\rightarrow \\bar{\\mathbb{R}}\\) that maps events to the extended real line is called a random variable (r.v.).\n\n\nA fully formal defition of a random variable involves a concept of measurability, which we would like to avoid defining at this point.\nLater in the notes, we will see random variables satisfying \\(\\text{Pr}(X = \\infty) &gt; 0\\). Hence, we map \\(\\Omega\\) to \\(\\bar{\\mathbb{R}} = \\mathbb{R}\\bigcup\\{\\pm\\infty\\}\\).\n\n\n\n\n\n\nDefinition\n\n\n\nFor events \\(A\\) and \\(B\\) in \\(\\Omega\\) we define conditional probability as \\[\\begin{equation*}\n\\text{Pr}\\left(B \\,|\\,A\\right) = \\frac{\\text{Pr}\\left(A \\bigcap B \\right)}{\\text{Pr}\\left(A \\right)}.\n\\end{equation*}\\] If \\(\\text{Pr}\\left(B \\,|\\,A\\right) = \\text{Pr}\\left(B \\right)\\) we say that the events \\(A\\) and \\(B\\) are independent, which together with the formula above implies that \\(\\text{Pr}\\left(A \\bigcap B \\right) = \\text{Pr}\\left(A \\right) \\times \\text{Pr}\\left(B \\right)\\).\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nTwo r.v.s \\(X\\) and \\(Y\\) are called independent if the events \\(\\{X \\in A\\}\\) and \\(\\{Y \\in B\\}\\) are independent for all sets \\(A\\) and \\(B\\).\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA sequence \\(X_1, \\dots X_n\\) of random variables is called iid (independent and identically distributed) if they are mutually independent and have the same distribution.\n\n\n\n\n\n\n\n\nExample: Bernoulli r.v.\n\n\n\nRandom variable \\(X \\in \\{0,1\\}\\) with \\(\\text{Pr}\\left(X=1 \\right)=p\\), \\(\\text{Pr}\\left(X=0 \\right)=1-p\\) for \\(0 \\le p \\le 1\\) is called a Bernoulli random variable with parameter (or success probability) \\(p\\).\n\n\n\n\n\n\n\n\nExample: Binomial r.v.\n\n\n\nLet \\(X_1,\\dots,X_n\\) be \\(n\\) independent \\(\\text{Bernoulli}(p)\\) random variables. Then the number of successes \\(S_n = \\sum_{i=1}^n X_i\\) is called a binomial r.v. with \\[\\begin{equation*}\n  \\text{Pr}\\left(S_n=k \\right) = {n \\choose k} p^k (1-p)^{n-k}, k = 0,\\dots, n.\n  \\end{equation*}\\]\n\n\n\n\n\n\n\n\nExample: Geometric r.v.\n\n\n\nLet \\(X_1, X_2, \\dots\\) be and infinite number of independent \\(\\text{Bernoulli}(p)\\) random variables and \\(N = \\min\\{n: X_n=1\\}\\) be the number of trials until the first success occurs, including the successful trial. Then \\[\\begin{equation*}\n    \\text{Pr}\\left(N=n \\right) = (1-p)^{n-1}p  \\text{ for } n=1,2,\\dots\n    \\end{equation*}\\]\n\n\nNote that there is an alternative definition of the geometric distribution does not count the successful trial so that \\(\\text{Pr}\\left(N=n \\right) = (1-p)^np \\text{ for } n=0,1,\\dots\\)\nWe defined all discrete random variables above using probabilities of \\(X\\) taking a particular value. A function that assigns probabilities to random variable values is called a probability mass function. However, a more general way to define random variables is by specifying a cumulative distribution function.\n\n\n\n\n\n\nDefinition\n\n\n\n\\(F(x) = \\text{Pr}\\left(X \\le x \\right)\\) is called the cumulative distribution function (cdf) of \\(X\\).\n\n\nProperties of cdf:\n\n\\(0 \\le F(x) \\le 1\\),\n\\(F(x) \\le F(y)\\) for \\(x \\le y\\),\n\\(\\lim_{x \\rightarrow y^{+}} F(x) = F(y)\\) (\\(F(x)\\) is right-continuous),\n\\(\\lim_{x \\rightarrow -\\infty} F(x) = \\text{Pr}\\left(X=-\\infty \\right)\\) (usually \\(=0\\)),\n\\(\\lim_{x \\rightarrow \\infty} F(x) = 1-\\text{Pr}\\left(X=\\infty \\right)\\) (usually \\(=1\\)),\n\\(\\text{Pr}\\left(X=x \\right) = F(x) - F(x-)\\) where \\(F(x-) = \\lim_{y \\uparrow x} F(y)\\).\n\n\n\n\n\n\n\nExample: Discrete uniform random variable\n\n\n\nFor a random variable \\(U\\), uniformly distributed over \\(\\{1,2,\\dots,n\\}\\), its cdf is given by \\[\\begin{equation*}\n  F(x) =\n  \\begin{cases}\n  0 &\\text{ if } x &lt; 1,\\\\\n1/n &\\text { if } 1 \\le x &lt; 2,\\\\\n  2/n &\\text { if } 2 \\le x &lt; 3,\\\\\n  &\\vdots\\\\\n(n-1)/n &\\text { if } n-1 \\le x &lt; n,\\\\\n  1 &\\text{ if } x \\ge n.\n  \\end{cases}\n  \\end{equation*}\\] The probability mass function and cdf of U, with \\(n=10\\), are shown in Figure 2.2, which also contains the probability mass function and cdf of a geometric random variable.\n\n\n\n\n\n\n\n\n\n\nFigure 2.2: Probability mass function (pmf) and cumulative distribution functions (cdf) for the discrete uniform random variable over the integer set \\(\\{1,2,\\dots,10\\}\\)\n\n\n\n\n\n\nmy.s.prob=0.2\n\nplot(c(0:14), dgeom(c(0:14),prob=my.s.prob), type=\"h\", xlab=\"X\", ylab=\"\", main=\"Geometric pmf\", axes=FALSE, ylim=c(0,1), lwd=2)\naxis(1, at=c(0:14))\naxis(2)\nbox()\n\n\n\n\n\n\n\nx&lt;-0:14\ncdf&lt;-pgeom(x,prob=my.s.prob)\n\nleftPointX = c(-0.5,x) \nleftPointY = c(0,cdf)\nrightPointX = c(x,14.5)\nrightPointY = c(0, cdf)\nplot(1,1,type=\"n\", xlim=c(-0.5,14.5), ylim = c(0,1),xlab=\"X\", ylab=\"\", main=\"Geometric cdf\")\nsegments(leftPointX, leftPointY, rightPointX-0.2, rightPointY,lwd=2)\npoints(x,c(0,cdf[-15]), cex=1.3)\npoints(x,cdf, cex=1.3, pch=19)\n\n\n\n\n\n\n\n#par(mfrow=c(2,2), cex.lab=1.4, cex.axis=1.4, cex.main=1.4)\nplot(1, 1, type=\"n\", main=\"Continuous uniform pdf\",\n     axes=FALSE, xlab=\"U\", ylab=\"Density\", ylim=c(0,1), xlim=c(-0.5,1.5), lwd=2)\nsegments(0,1,1,1, lwd=2)\nsegments(-0.5,0,-0.05,0, lwd=2)\nsegments(1.05,0,1.5,0, lwd=2)\npoints(c(0,1), c(0,0), cex=1.3)\npoints(c(0,1), c(1,1), cex=1.3, pch=19)\naxis(1)\naxis(2)\nbox()\n\n\n\n\n\n\n\nplot(1, 1, type=\"n\", main=\"Continuous uniform cdf\",\n     axes=FALSE, xlab=\"U\", ylab=\"Probability\", ylim=c(0,1), xlim=c(-0.5,1.5), lwd=2)\nsegments(0,0,1,1, lwd=2)\nsegments(-0.5,0,0,0, lwd=2)\nsegments(1,1,1.5,1, lwd=2)\naxis(1)\naxis(2)\nbox()\n\n\n\n\n\n\n\nx.grid = c(0,1:1000)/100\nmy.lambda = 2.4\n\nplot(x.grid, dexp(x.grid, rate=my.lambda), type=\"l\", main=\"Exponential pdf\",\n     axes=FALSE, xlab=\"X\", ylab=\"Density\", xlim=c(0,3), lwd=2)\naxis(1)\naxis(2)\nbox()\n\n\n\n\n\n\n\nplot(x.grid, pexp(x.grid, rate=my.lambda), type=\"l\", main=\"Exponential cdf\",\n     axes=FALSE, xlab=\"X\", ylab=\"Probability\", ylim=c(0,1.0), xlim=c(0,3), lwd=2)\naxis(1)\naxis(2)\nbox()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability Refresher</span>"
    ]
  },
  {
    "objectID": "prob_refresh.html#expectations",
    "href": "prob_refresh.html#expectations",
    "title": "2  Probability Refresher",
    "section": "2.3 Expectations",
    "text": "2.3 Expectations",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability Refresher</span>"
    ]
  },
  {
    "objectID": "prob_refresh.html#limit-theorems",
    "href": "prob_refresh.html#limit-theorems",
    "title": "2  Probability Refresher",
    "section": "2.4 Limit Theorems",
    "text": "2.4 Limit Theorems\n\n\n\n\nDurret, R. 2004. Probability: Theory and Examples. Third. Duxbury Press.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability Refresher</span>"
    ]
  },
  {
    "objectID": "prob_refresh.html#footnotes",
    "href": "prob_refresh.html#footnotes",
    "title": "2  Probability Refresher",
    "section": "",
    "text": "We use the term state space, which is frequently used in stochastic processes theory. In probability textbooks the term sample space is more common.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability Refresher</span>"
    ]
  }
]