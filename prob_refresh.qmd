::: {.content-hidden}
    {{< include _macros.qmd >}}
:::

# Probability Refresher

Here, we review some probability concepts that will be used repeatedly in the subsequent chapters. Material here succinctly covers what students typically see in a mathematically rigorous class on probability theory. 

## Events and their Probabilities 

A **random experiment or process** is one where deterministic prediction is difficult. 
A coin toss is an example of a random experiment. Random experiments generate **simple events**. 
For example, if you toss a coin twice, the simple events are: HH, HT, TH, TT, where H = heads and T = tails.

::: {.callout-note  icon=false appearance="simple" title="Definition"}

The **state space**[^1] $\Omega$ is a collection of all possible outcomes of a random experiment.
:::


[^1]: We use the term *state space*, which is frequently used in stochastic processes theory. In probability textbooks the term *sample space* is more common. 

For the tossing a coin twice experiment, the sample space is $S=\{HH, HT, TH, TT\}$.

::: {.callout-note  icon=false appearance="simple" title="Definition"}
An **event** is any subset of the state space. 
:::

For the coin-tossing experiment, we can define the following events:

- $A = \text{"at least one H"} \Rightarrow A=\{HH, HT, TH\}$ 
-  $B = \text{"at most one H"} \Rightarrow B=\{HT, TH, TT\}$

::: {.callout-note  icon=false appearance="simple" title="Definition of event/set arithmetic"}
* $A \cup B = \{\text{simple events in A or B or both}\}$
* $A \cap B = \{\text{simple events in both A and B}\}$ 
* $A^c = \{\text{simple events not in A}\}$
:::

For the two-coin-tossing example with events A and B:

- $A \cup B = \{HH, HT, TH, TT\} = S$ (the whole state space)
- $A \cap B = \{HT, TH\}$
- $A^c = \{TT\}$
- $B^c = \{HH\}$


Since events are sets, it is often useful to visualize them with Venn diagrams. 

```{r}
#| fig-cap: A Venn diagram showing two events of ,  $A=\{HH, HT, TH\}$ and $B=\{HT, TH, TT\}$, and their intersection $A \cup B = \{HT, TH\}$.
#| label: fig-venn-coin-toss
#| echo: false
#| message: false
#| warning: false
#| out.width: 60%

library(VennDiagram)
library(grid)

# Define set sizes (these numbers aren't shown but determine circle size/position)
area1 <- 100
area2 <- 100
cross.area <- 50

# Draw a pairwise Venn diagram without printing default labels/numbers
venn.plot <- draw.pairwise.venn(
  area1 = area1,
  area2 = area2,
  cross.area = cross.area,
  category = c("", ""),         # leave outer category labels empty
  fill = c("lightblue", "pink"),
  print.mode = "none"           # suppress numeric labels
)

# Render the (empty) diagram
grid.draw(venn.plot)

# Add custom set labels inside the circles.
# Adjust the x and y coordinates as needed.
grid.text("HH", x = 0.2, y = 0.5, gp = gpar(fontsize = 16, col = "black"))
grid.text("TT", x = 0.85, y = 0.5, gp = gpar(fontsize = 16, col = "black"))
# Add intersection label centered between the circles
grid.text("TH", x = 0.5, y = 0.65, gp = gpar(fontsize = 16, col = "black"))
grid.text("HT", x = 0.5, y = 0.35, gp = gpar(fontsize = 16, col = "black"))
```

The **De Morgan Laws** allow us to take complements of unions and intersections of sets/events:

- $(A \cup B)^c = A^c \cap B^c$
- $(A \cap B)^c = A^c \cup B^c$ 


If events $A$ and $B$ cannot happen at the same time, they are called **mutually exclusive**. In set notations this means that their intersection is an empty set: $A \cap B = \emptyset$.


## Probability axioms

[cite_start]**Probability** is a function that maps events to real numbers between 0 and 1[cite: 110, 114, 115, 116, 117, 118].

The probability axioms are:
1.  [cite_start]For any event $A \subset S$, $0 \le P(A) \le 1$[cite: 121, 122, 125, 126].
2.  [cite_start]$P(S) = 1$[cite: 122].
3.  [cite_start]For mutually exclusive events A and B ($A \cap B = \emptyset$), $P(A \cup B) = P(A) + P(B)$[cite: 127].

[cite_start]The **General Addition Rule** is: $P(A \cup B) = P(A) + P(B) - P(A \cap B)$[cite: 127].

[cite_start]The **Law of Complementary Events** is: $P(A^c) = 1 - P(A)$[cite: 132].

### Example: practicing addition rule

Suppose we know the following probabilities for students in a Stats 67 class:
* [cite_start]Probability of being right-handed: $P(A) = 0.8$ [cite: 144]
* [cite_start]Probability of being a CS major: $P(B) = 0.87$ [cite: 144]
* [cite_start]Probability of being both right-handed and a CS major: $P(A \cap B) = 0.75$ [cite: 144, 145]

[cite_start]What is the probability that a student is either right-handed, a CS major, or both? [cite: 146, 147, 148, 149, 150, 151]

We can use the addition rule:
[cite_start]$P(A \cup B) = P(A) + P(B) - P(A \cap B)$ [cite: 159]
[cite_start]$P(A \cup B) = 0.8 + 0.87 - 0.75 = 0.92$ [cite: 160]

[cite_start]**Next question:** What is the probability that a Stats 67 student is a left-handed CS major? [cite: 161, 162, 163, 164, 165, 166, 167]
[cite_start]We need to find $P(A^c \cap B)$, where $A^c$ represents a student who is not right-handed (i.e., left-handed)[cite: 169, 170].

[cite_start]A useful trick to remember is that for any events A and B, we can write $B = (A^c \cap B) \cup (A \cap B)$[cite: 175]. Since $(A^c \cap B)$ and $(A \cap B)$ are disjoint, we can apply the addition rule:
[cite_start]$P(B) = P(A^c \cap B) + P(A \cap B)$ [cite: 186]

Now we can solve for $P(A^c \cap B)$:
[cite_start]$P(A^c \cap B) = P(B) - P(A \cap B)$ [cite: 193]
[cite_start]$P(A^c \cap B) = 0.87 - 0.75 = 0.12$ [cite: 193, 195]

We assume that we can assign probabilities to *events* --- outcomes of a random experiment. 
For example, tossing a coin results in one of two possible events: H ="heads" and T="tails." 
More formally, we define **events** as certain subsets of some abstract space. 





Next, we need to be able to assign probabilities to events. This is done by introducing a probability measure.

::: {.callout-note  icon=false appearance="simple" title="Definition"}

 A **probability measure** $\text{Pr}(\cdot)$ is a function mapping subsets of $\Omega$ to real numbers, 
  satisfying:

  - $\text{Pr}(\Omega) = 1$.
  - $0 \le \text{Pr}(A) \le 1$ for all $A \subset \Omega$.
  - $\text{Pr}\left(\bigcup_{i=1}^{\infty} A_i \right) = 
    \sum_{i=1}^{\infty}\text{Pr}(A_i)$ for *mutually exclusive* events $A_1,A_2,\dots$ 

:::

 In the case of countable $\Omega$ we can define $\text{Pr}(\cdot)$ for all subsets, while if the cardinality is larger we have to restrict attention to certain subsets, called measuarble [@DurretProbBook].

::: {.callout-caution icon=false appearance="simple" title="Example"}

  Let $\Omega = \{1,2,\dots,n\}$, we  define $\prob{A} = |A|/n$, where $|A|$ is the number of elements in $A \in \Omega$. For example, 
  if $n=10$, then $\prob{\{1\}} = 0.1$ and $\prob{\{2,9,10\}} = 0.3$.

:::

We also need a concept of a random variable. Informally, a random variable $X$ is a function or variable, whose value is generated by a random experiment. For example, we can define a binary random variable associated with a toss of a coin:
\begin{equation*}
X = 
\begin{cases}
1 &\text{ if heads},\\
0 &\text{ if tails}.
\end{cases}
\end{equation*}

More generally:

::: {.callout-note  icon=false appearance="simple" title="Definition"}

  A function $X(\omega): \Omega \rightarrow \bar{\mathbb{R}}$ that maps events to the extended real line is called a **random variable (r.v.)**.

:::

A fully formal defition of a random variable involves a concept of measurability, which we would like to avoid defining at this point.

Later in the notes, we will see random variables satisfying $\text{Pr}(X = \infty) > 0$. 
Hence, we map $\Omega$ to $\bar{\mathbb{R}} = \mathbb{R}\bigcup\{\pm\infty\}$.

::: {.callout-note icon=false appearance="simple" title="Definition"}
For events $A$ and $B$ in $\Omega$ we define **conditional probability** as
\begin{equation*}
\cprob{B}{A} = \frac{\prob{A \bigcap B}}{\prob{A}}.
\end{equation*}
If  $\cprob{B}{A} = \prob{B}$ we say that the **events $A$ and $B$ are independent**, which together with the formula above 
implies that $\prob{A \bigcap B} = \prob{A} \times \prob{B}$.
:::

::: {.callout-note icon=false appearance="simple" title="Definition"}
Two **r.v.s $X$ and $Y$ are called independent** if the events $\{X \in A\}$ and $\{Y \in B\}$ are independent for all sets $A$ and $B$. 
:::

::: {.callout-note icon=false appearance="simple" title="Definition"}
A sequence $X_1, \dots X_n$ of random variables is called **iid (independent and identically distributed)** if they are mutually independent and have the same distribution.
:::

::: {.callout-caution icon=false appearance="simple" title="Example: Bernoulli r.v."}
  
  Random variable $X \in \{0,1\}$ with $\prob{X=1}=p$, $\prob{X=0}=1-p$ for $0 \le p \le 1$ is called a **Bernoulli** random variable with parameter (or success probability) $p$.
:::

::: {.callout-caution icon=false appearance="simple" title="Example: Binomial r.v."}
  Let $X_1,\dots,X_n$ be $n$ independent $\text{Bernoulli}(p)$ random variables. Then the number of successes 
  $S_n = \sum_{i=1}^n X_i$ is called a **binomial r.v.** with 
  \begin{equation*}
  \prob{S_n=k} = {n \choose k} p^k (1-p)^{n-k}, k = 0,\dots, n.
  \end{equation*}
:::

::: {.callout-caution icon=false appearance="simple" title="Example: Geometric r.v."}
  Let $X_1, X_2, \dots$ be and infinite number of independent $\text{Bernoulli}(p)$ random variables and 
  $N = \min\{n: X_n=1\}$ be the number of trials until the first success occurs, including 
    the successful trial. Then
    \begin{equation*}
    \prob{N=n} = (1-p)^{n-1}p  \text{ for } n=1,2,\dots
    \end{equation*}
:::

Note that there is an alternative definition of the geometric distribution does not count the successful trial so that $\prob{N=n} = (1-p)^np \text{ for } n=0,1,\dots$

We defined all discrete random variables above using probabilities of $X$ taking a particular value. A function
that assigns probabilities to random variable values is called a **probability mass function**. However, a more
general way to define random variables is by specifying a **cumulative distribution function**.

::: {.callout-note title="Definition"}
$F(x) = \prob{X \le x}$ is called the **cumulative distribution function (cdf)** of $X$.
:::

Properties of cdf:

1. $0 \le F(x) \le 1$,
2. $F(x) \le F(y)$ for $x \le y$,
3. $\lim_{x \rightarrow y^{+}} F(x) = F(y)$ ($F(x)$ is right-continuous),
4. $\lim_{x \rightarrow -\infty} F(x) = \prob{X=-\infty}$ (usually $=0$),
5. $\lim_{x \rightarrow \infty} F(x) = 1-\prob{X=\infty}$ (usually $=1$),
6. $\prob{X=x} = F(x) - F(x-)$ where $F(x-) = \lim_{y \uparrow x} F(y)$.

::: {.callout-caution icon=false appearance="simple" title="Example: Discrete uniform random variable"}
For a random variable $U$, uniformly distributed over $\{1,2,\dots,n\}$, its cdf is given by
  \begin{equation*}
  F(x) = 
  \begin{cases}
  0 &\text{ if } x < 1,\\
 1/n &\text { if } 1 \le x < 2,\\
  2/n &\text { if } 2 \le x < 3,\\
  &\vdots\\
(n-1)/n &\text { if } n-1 \le x < n,\\
  1 &\text{ if } x \ge n.
  \end{cases} 
  \end{equation*}
  The probability mass function and cdf of U, with $n=10$, are shown in @fig-discr-unif-pdf-cdf, which also contains the probability mass function and cdf of a geometric random variable.
:::


```{r}
#| fig-cap: Probability mass function (pmf) and cumulative distribution functions (cdf) for the discrete uniform random variable over the integer set $\{1,2,\dots,10\}$
#| label: fig-discr-unif-pdf-cdf
#| echo: false
#| message: false
#| warning: false
#| out.width: 100%

par(mfrow=c(1,2), cex=0.8, mar = c(5, 4, 6, 2) + 0.1)
plot(c(1:10), rep(1/10,10), type="h", xlab="u", ylab="Probability", main="Discrete uniform pmf", axes=FALSE, ylim=c(0,1), lwd=2)
axis(1, at=c(1:10))
axis(2, at=c(0:10)/10)
box()

leftPointX = c(-0.5, 1:10)
leftPointY = c(0, c(1:10)/10)

rightPointX = c(1:10, 11.5)
rightPointY = c(0, c(1:10)/10)

par(mar = c(5, 1, 6, 2) + 0.1)

plot(1,1, type="n", xlim=c(-0.5,11.5), ylim=c(0,1),
     xlab="u", ylab="", main="Discrete uniform cdf", axes=FALSE)
segments(leftPointX, leftPointY, rightPointX-0.2, rightPointY, lwd=2)
points(c(1:10), c(0:9)/10, cex=1.3)
points(c(1:10), c(0:9)/10+1/10, cex=1.3, pch=19)
axis(1, at=c(1:10))
box()
```



```{r}
my.s.prob=0.2

plot(c(0:14), dgeom(c(0:14),prob=my.s.prob), type="h", xlab="X", ylab="", main="Geometric pmf", axes=FALSE, ylim=c(0,1), lwd=2)
axis(1, at=c(0:14))
axis(2)
box()

x<-0:14
cdf<-pgeom(x,prob=my.s.prob)

leftPointX = c(-0.5,x) 
leftPointY = c(0,cdf)
rightPointX = c(x,14.5)
rightPointY = c(0, cdf)
plot(1,1,type="n", xlim=c(-0.5,14.5), ylim = c(0,1),xlab="X", ylab="", main="Geometric cdf")
segments(leftPointX, leftPointY, rightPointX-0.2, rightPointY,lwd=2)
points(x,c(0,cdf[-15]), cex=1.3)
points(x,cdf, cex=1.3, pch=19)


#par(mfrow=c(2,2), cex.lab=1.4, cex.axis=1.4, cex.main=1.4)
plot(1, 1, type="n", main="Continuous uniform pdf",
     axes=FALSE, xlab="U", ylab="Density", ylim=c(0,1), xlim=c(-0.5,1.5), lwd=2)
segments(0,1,1,1, lwd=2)
segments(-0.5,0,-0.05,0, lwd=2)
segments(1.05,0,1.5,0, lwd=2)
points(c(0,1), c(0,0), cex=1.3)
points(c(0,1), c(1,1), cex=1.3, pch=19)
axis(1)
axis(2)
box()


plot(1, 1, type="n", main="Continuous uniform cdf",
     axes=FALSE, xlab="U", ylab="Probability", ylim=c(0,1), xlim=c(-0.5,1.5), lwd=2)
segments(0,0,1,1, lwd=2)
segments(-0.5,0,0,0, lwd=2)
segments(1,1,1.5,1, lwd=2)
axis(1)
axis(2)
box()

x.grid = c(0,1:1000)/100
my.lambda = 2.4

plot(x.grid, dexp(x.grid, rate=my.lambda), type="l", main="Exponential pdf",
     axes=FALSE, xlab="X", ylab="Density", xlim=c(0,3), lwd=2)
axis(1)
axis(2)
box()

plot(x.grid, pexp(x.grid, rate=my.lambda), type="l", main="Exponential cdf",
     axes=FALSE, xlab="X", ylab="Probability", ylim=c(0,1.0), xlim=c(0,3), lwd=2)
axis(1)
axis(2)
box()
```

\caption{Probability mass functions (pmfs) and cumulative distribution functions (cdfs) for the discrete uniform 
random variable over $\{1,2,\dots,10\}$ and for the geometric random variable with success probability $p = \Sexpr{my.s.prob}$ (top row).
Probability density functions (pdfs) and cdfs for the continuous uniform random variable over $[0,1]$ and for the exponential random variable 
with rate parameter $\lambda = 2.4$ (bottom row).}



## Expectations

## Limit Theorems