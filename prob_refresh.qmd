::: {.content-hidden}
    {{< include _macros.qmd >}}
:::

# Probability Refresher

Here, we review some probability concepts that will be used repeatedly in the subsequent chapters. Material here succinctly covers what students typically see in a mathematically rigorous class on probability theory. 
In US, such classes are usually offered by Mathematics and Statistics departments. 

We assume that we can assign probabilities to *events* --- outcomes of a random experiment. 
For example, tossing a coin results in one of two possible events: H =``heads" and T=``tails." 
More formally, we define *events* as certain subsets of some abstract space. 


::: {.callout-note icon=false appearance="simple"}

## Definition

The *state space*[^1] $\Omega$ is a collection of all possible outcomes of a random experiment.

:::


[^1]: We use the term *state space*, which is frequently used in stochastic processes theory. In probability textbooks the term *sample space* is more common. 


Next, we need to be able to assign probabilities to events. This is done by introducing a probability measure.

::: {.callout-note icon=false appearance="simple"}

## Definition

 A \textit{probability measure} $\text{Pr}(\cdot)$ is a function mapping subsets of $\Omega$ to real numbers, 
  satisfying:

  - $\text{Pr}(\Omega) = 1$.
  - $0 \le \text{Pr}(A) \le 1$ for all $A \subset \Omega$.
  - $\text{Pr}\left(\bigcup_{i=1}^{\infty} A_i \right) = 
    \sum_{i=1}^{\infty}\text{Pr}(A_i)$ for *mutually exclusive* events $A_1,A_2,\dots$ 

:::

 In the case of countable $\Omega$ we can define $\text{Pr}(\cdot)$ for all subsets, while if the cardinality is larger we have to restrict attention to certain subsets, called measuarble [@DurretProbBook].

::: {.callout-note icon=false appearance="simple"}

## Example

  Let $\Omega = \{1,2,\dots,n\}$, we  define $\prob{A} = |A|/n$, where $|A|$ is the number of elements in $A \in \Omega$. For example, 
  if $n=10$, then $\prob{\{1\}} = 0.1$ and $\prob{\{2,9,10\}} = 0.3$.

:::

We also need a concept of a random variable. Informally, a random variable $X$ is a function or variable, whose value is generated by a random experiment. For example, we can define a binary random variable associated with a toss of a coin:
\begin{equation*}
X = 
\begin{cases}
1 &\text{ if heads},\\
0 &\text{ if tails}.
\end{cases}
\end{equation*}

More generally:

::: {.callout-note icon=false appearance="simple"}

## Definition

  A function $X(\omega): \Omega \rightarrow \bar{\mathbb{R}}$ is called a *random variable* (r.v.).

:::

A fully formal defition of a random variable involves a concept of measurability, which we would like to avoid defining at this point.

Later in the notes, we will see random variables satisfying $\text{Pr}(X = \infty) > 0$. 
Hence, we map $\Omega$ to $\bar{\mathbb{R}} = \mathbb{R}\bigcup\{\pm\infty\}$.